<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>A Raspberry PI Concourse Worker | Rahul Vishwakarma Blog</title>
    <link rel="stylesheet" type="text/css" href="../styles.css" media="screen" />
</head>
<body>
<header>
    <nav>
        <a href="/index.html" aria-label="Go back to the homepage">← Back</a>
        <a href="https://ops.tips/blog/raspberry-pi-concourse-ci-worker/" target="_blank" rel="noopener noreferrer">
            View Original
        </a>
    </nav>
</header>

<main>
    <article>
        <h1>A Raspberry PI Concourse Worker</h1>
        <section>
            
            <div id="readability-page-1" class="page"><article itemtype="http://schema.org/NewsArticle">
    <section itemprop="articleBody">
      <p>Hey,</p>
<p>I’ve recently bought a <a href="https://www.raspberrypi.org/products/raspberry-pi-3-model-b-plus/">Raspberry Pi 3B+</a>, and that seemed like a great target for a <a href="https://concourse-ci.org">Concourse</a> worker run at.</p>
<figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/concourse-raspberry-pi-diagram.svg" alt="concourse cluster with the raspberry pi included "/>

    
</figure>

<p>It turns out that just the process of building and adapting the Concourse binary itself was already an interesting thing to do, so here I share the lessons learned and how that process looked like.</p>
<p>To provide <a href="https://en.wikipedia.org/wiki/ARM_architecture">ARM</a>-compiled binaries for <a href="https://github.com/cirocosta/node_extra_exporter"><code>node_extra_exporter</code></a> (a Rust-based <a href="https://prometheus.io/">Prometheus</a> exporter for exposing some metrics that the traditional <code>node_exporter</code> doesn’t expose), it felt like having an ARM-based machine in my Concourse cluster would be a great idea - have an extra job for building the ARM binary and there you go!</p>
<p>If you’d like to know what does it take to get a Concourse worker ready to take workloads on ARM, make sure you stick to the end.</p>
<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON&#39;T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
<ul>
<li><a href="#concourse-workers">Concourse workers</a></li>
<li><a href="#compiling-the-concourse-binary">Compiling the Concourse binary</a></li>
<li><a href="#cross-compiling-go-code">Cross compiling Go code</a></li>
<li><a href="#compiling-cgo-code">Compiling CGO code</a></li>
<li><a href="#cross-compiling-cgo-code">Cross compiling CGO code</a></li>
<li><a href="#building-guardian-the-containerizer">Building Guardian, the containerizer</a></li>
<li><a href="#building-baggageclaim-the-volumizer">Building Baggageclaim, the volumizer</a></li>
<li><a href="#running-the-concourse-worker">Running the Concourse worker</a></li>
<li><a href="#generating-the-modified-registry-image-resource">Generating the modified registry-image-resource</a></li>
<li><a href="#automating-the-process-of-building-an-arm-based-concourse-distribution">Automating the process of building an ARM-based Concourse distribution</a></li>
<li><a href="#summarizing">Summarizing</a></li>
<li><a href="#some-surprises">Some surprises</a></li>
<li><a href="#closing-thoughts">Closing Thoughts</a></li>
</ul>
<!-- END doctoc generated TOC please keep comment here to allow auto update -->
<h3 id="concourse-workers">Concourse workers</h3>
<p>Regardless of your knowledge of <a href="https://concourse-ci.org">Concourse</a>, the <em>tl;dr</em> is that being a “continuous thing-doer”, it needs some form of compute nodes to do the things you want - these nodes are the workers.</p>
<p>To perform the job of “doing things”, in any platform, these workers are made of three components:</p>
<ul>
<li>a “containerizer”, that manages containers</li>
<li>a “volumizer”, that manages volumes</li>
<li>“beacon”, the piece that registers the worker against the cluster and manages its lifecycle</li>
</ul>
<figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/concourse-architecture.svg" alt="minimal architecture showing the internal concourse components "/>

    
</figure>

<p>In the case of Linux, of those three components, two<sup>1</sup> (the “volumizer” and “beacon”) are already part of the <code>concourse</code> binary. This means that we not only need to build <code>concourse</code>, but we also need to build the “containerizer”.</p>
<p><em><sup>1</sup> there’s an expection, but that won’t be covered here.</em></p>
<h3 id="compiling-the-concourse-binary">Compiling the Concourse binary</h3>
<p>Being Concourse a project entirely written in Go (actually, there’s also the UI, which is in <a href="https://elm-lang.org/">Elm</a>), all that we need at this stage is the Go toolchain.</p>
<p>As almost all of the Go code necessary for building Concourse is now under a single repository (<a href="https://github.com/concourse/concourse"><code>github.com/concourse/concourse</code></a>), and <a href="https://github.com/golang/go/wiki/Modules">Go modules</a> is the way that dependencies are handled there, this is what should be the most straightforward part.</p>
<p>Given that installing Go is quite straightforward, I decided to do that right in my Raspberry PI (why not?).</p>
<figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/concourse-built-on-raspberry-pi.svg" alt="illustration of the concourse repository being built in a raspberry pi producing armv7 concourse "/>

    
</figure>

<p>This means that just the following two steps are required:</p>
<div><pre><code data-lang="sh"><span># clone the main concourse repository</span>
<span>#</span>
git clone https://github.com/concourse/concourse .


<span># build the main Concourse binary and put the result of</span>
<span># the compilation into `$GOPATH/bin/`.</span>
<span>#</span>
go install -v ./cmd/concourse
</code></pre></div><p>The problem though, is that the Raspberry PI is not as powerful as one would imagine: despite the 4 core <a href="https://en.wikipedia.org/wiki/System_on_a_chip">SoC</a>, it takes no less than seven minutes once all of the dependencies are already in place. Yeah, SEVEN MINUTES already having fetched all of the dependencies. Without the dependencies: 20 minutes.</p>
<figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/concourse-build-arm.svg" alt="graph showing the cpu utilization of the raspberry pi during the build process "/>

    
</figure>

<p>For a full picture of the dashboard, <a href="https://snapshot.raintank.io/dashboard/snapshot/URPBthXh5SGLi3HnxxLel1wkmwDQn06X?orgId=2">click here</a> to check out the interactive snapshot).</p>

<p>As a side note, it was quite interesting for me to see how there are clearly very different phases that the compiler toolchain goes trough when performing the build (not including the dependency fetching that is not in this panel).</p>
<h3 id="cross-compiling-go-code">Cross compiling Go code</h3>
<p>Knowing that if I’d need to recompile this multiple times, it’d be crazy slow and, thus, super time consuming, I decided to go with <a href="http://baruch.siach.name/blog/posts/introduction_to_cross_compilation_part_1/">cross compiling</a> - this way we could just use all of the speed we have available and, in the end, just ship the binaries.</p>
<figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/cross-compile.svg" alt="illustration of a macbook pro machine running darwin producing artifacts for other architectures and operating systems "/>

    
</figure>

<p>Another benefit is that it’d be easy for anyone to build it too! No need for an actual Raspberry PI (or any ARMv7) to build Concourse.</p>
<p>The good news is that Go makes that whole job easy for us, making the whole cross compilation dependant on just few flags:</p>
<ul>
<li><code>GOOS</code> the name of the target operating system</li>
<li><code>GOARCH</code> the name of the target architecture</li>
<li><code>GOARM</code> the version of ARM that want to target</li>
</ul>
<figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/go-compilation.svg" alt="illustration of a golang file going through the compilation steps that gets it towards a compiled binary file "/>

    
</figure>

<p>For Go code that is free of any calls to C code (via <a href="https://blog.golang.org/c-go-cgo"><code>CGO</code></a>), this “Just Works™” by the magic of the default Go toolchain - the go compilation infrastructure has all the necessary bits to perform the right translation to the right architectures and OSes that it supports.</p>
<div>

<p>If you’re curious about the intermediate representation that the Go compiler generates and how that becomes machine-dependant code, checkout the following example views of <a href="https://godoc.org/golang.org/x/tools/go/ssa">Go’s SSA</a>:</p>
<ul>
<li><a href="https://ops.tips/blog/-/general/ssa-linux-amd64">Linux AMD64</a></li>
<li><a href="https://ops.tips/blog/-/general/ssa-linux-arm64">Linux ARM64</a></li>
</ul>
<p>ps.: to compile reproduce: <code>GOSSAFUNC=main go build -gcflags &#34;-S&#34; main.go</code></p>

</div>

<p>However, being free of calls to C code is not a property of all projects  - in the case of Concourse itself, <a href="https://github.com/dexidp/dex"><code>dex</code></a>, one of our dependencies, depends on <a href="https://github.com/mattn/go-sqlite3"><code>go-sqlite3</code></a>, which has bindings to C, which means that we now depend on CGO.</p>
<pre><code>├ github.com/concourse/concourse/skymarshal/storage
  ├ github.com/concourse/dex/storage
  ├ github.com/concourse/dex/storage/sql
    ├ database/sql
    ├ database/sql/driver
    ...
    └ github.com/mattn/go-sqlite3
      ├ database/sql
      ├ database/sql/driver
      ..
      ├ unsafe
      └ C                       &lt;&lt; CGO!!
</code></pre><p>If you’re curious about an example in <code>go-sqlite3</code> where CGO gets used, check out <a href="https://github.com/mattn/go-sqlite3/blob/2a192bf7823799e082cfa3380aab9f02e4d312c0/sqlite3.go#L179-L203">sqlite3.go</a>.</p>

<p>To see what I mean by “CGO doesn’t ‘just works’”, let’s try doing cross compilation with just those flags:</p>
<div><pre><code data-lang="sh"><span>CGO_ENABLED</span><span>=</span><span>1</span> <span>\
</span><span></span>        <span>GOARCH</span><span>=</span>arm <span>\
</span><span></span>        <span>GOARM</span><span>=</span><span>7</span> <span>\
</span><span></span>        <span>GOOS</span><span>=</span>linux <span>\
</span><span></span>                go build ./cmd/concourse/
<span># runtime/cgo</span>
gcc: error: unrecognized <span>command</span> line option <span>&#39;-marm&#39;</span><span>;</span> 
            did you mean <span>&#39;-mabm&#39;</span>?
</code></pre></div><p>And the reason why it wouldn’t work out of the box makes sense: when it comes to CGO, you’re not only in the realm of the Go toolchain, but you’re also relying on the infrastructure to build the C code as well, and there, things are slightly different. Let’s expand on it.</p>
<h3 id="compiling-cgo-code">Compiling CGO code</h3>
<p>As an example of how cross compilation with CGO looks like, let’s assume that we have a super extra very efficient library in C that is optimized to print strings to <code>stdout</code>.</p>
<figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/go-calling-c.svg" alt="illustration of building CGO code "/>

    
</figure>

<p>First, starting with the declaration of the function we want to consume from Go (in the <code>printer.h</code> file):</p>
<div><pre><code data-lang="c"><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span><span></span><span>void</span> <span>super_optimized_print</span><span>(</span><span>char</span><span>*</span> <span>str</span><span>);</span>
</code></pre></div><p>Then, in the definition (<code>printer.c</code>):</p>
<div><pre><code data-lang="c"><span>#include</span> <span>&#34;printer.h&#34;</span><span>
</span><span></span><span>void</span> <span>super_optimized_print</span><span>(</span><span>char</span><span>*</span> <span>str</span><span>)</span>
<span>{</span>
	<span>printf</span><span>(</span><span>&#34;%s</span><span>\n</span><span>&#34;</span><span>,</span> <span>str</span><span>);</span>
	<span>return</span><span>;</span>
<span>}</span>
</code></pre></div><p>And now, finally, our Go code that uses CGO (<code>main.go</code>):</p>
<div><pre><code data-lang="go"><span>package</span> <span>main</span>

<span>// #include &#34;printer.h&#34;
</span><span>// #include &lt;stdlib.h&gt;
</span><span></span><span>import</span> <span>&#34;C&#34;</span>
<span>import</span> <span>&#34;unsafe&#34;</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>str</span> <span>:=</span> <span>C</span><span>.</span><span>CString</span><span>(</span><span>&#34;hello world&#34;</span><span>)</span>
	<span>defer</span> <span>C</span><span>.</span><span>free</span><span>(</span><span>unsafe</span><span>.</span><span>Pointer</span><span>(</span><span>str</span><span>))</span>

	<span>C</span><span>.</span><span>super_optimized_print</span><span>(</span><span>str</span><span>)</span>
<span>}</span>
</code></pre></div><p>We can then try to build all of that code to our own OS and ARCH, and nothing really needs to be changed: you give the package to the <code>go</code> compiler, and let it do its job:</p>
<p>As, in this case, our C code is definitely portable, and we’re targetting our own machine architecture, all works. Let’s now try to build to a different platform though.</p>
<h3 id="cross-compiling-cgo-code">Cross compiling CGO code</h3>
<p>However, if, again, we try the cross compilation, it’ll fail with the very same error we saw before:</p>
<div><pre><code data-lang="sh"><span>CGO_ENABLED</span><span>=</span><span>1</span> <span>GOOS</span><span>=</span>linux <span>GOARCH</span><span>=</span>arm <span>GOARM</span><span>=</span><span>7</span> go build -v .
gcc: error: unrecognized <span>command</span> line 
     option <span>&#39;-marm&#39;</span><span>;</span> did you mean <span>&#39;-mabm&#39;</span>?
</code></pre></div><p>The good news is that without even looking at the Go code, we can see how that separation of “who compiles what” happens by tracing all of the <a href="https://linux.die.net/man/2/execve"><code>execve</code></a>s that happen:</p>
<pre><code>PCOMM     PID      PPID     ARGS
--------------------------------------------------------
go        29352    26142    go build .
cgo       29361    29352    cgo -V=full
compile   29362    29352    compile -V=full
compile   29365    29352    compile -V=full
compile   29367    29352    compile -V=full
compile   29376    29352    compile -V=full
asm       29381    29352    asm -V=full
asm       29382    29352    asm -V=full
cgo       29394    29352    cgo -objdir /tmp/go-build123931463/b003/...
gcc       29399    29394    gcc -E -dM -marm -I /tmp/go-build1239314...
</code></pre><figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/cgo-gcc-execsnoop.svg" alt="diagram with the steps taken by the compiler to cross-compile CGO "/>

    
</figure>



<p>And that seems perfectly reasonable - to build <code>C</code> code, one needs to have a C compiler, which is something totally out of the realm of where the Go team should be focusing on, reason why it calls out to a C compiler.</p>
<p>The failure that we see there though comes from the fact that to have <a href="https://gcc.gnu.org/">GCC</a> performing the cross compilation, we need to install separate packages before, and properly adjust the C compiler to point to the right compiler.</p>
<p>Luckly, letting Go know which compiler to use when performing the build comes down to setting the <code>CC</code> environment variable (see <a href="https://github.com/golang/go/blob/master/src/cmd/cgo/gcc.go#L1514-L1528"><code>golang/go#gccBaseCmd()</code></a>).</p>
<div><pre><code data-lang="sh"><span>CGO_ENABLED</span><span>=</span><span>1</span> <span>\
</span><span></span>        <span>GOOS</span><span>=</span>linux <span>\
</span><span></span>        <span>GOARCH</span><span>=</span>arm <span>\
</span><span></span>        <span>GOARM</span><span>=</span><span>7</span> <span>\
</span><span></span>        <span>CC</span><span>=</span>arm-linux-gnueabihf-gcc <span>\
</span><span></span>        go build -v
<span># workkss!!</span>

PCOMM     PID    PPID   ARGS
go        <span>30825</span>  <span>26142</span>  go build -v .
cgo       <span>30834</span>  <span>30825</span>  cgo -V<span>=</span>full
compile   <span>30835</span>  <span>30825</span>  compile -V<span>=</span>full
compile   <span>30840</span>  <span>30825</span>  compile -V<span>=</span>full
compile   <span>30841</span>  <span>30825</span>  compile -V<span>=</span>full
compile   <span>30842</span>  <span>30825</span>  compile -V<span>=</span>full
asm       <span>30857</span>  <span>30825</span>  asm -V<span>=</span>full
asm       <span>30862</span>  <span>30825</span>  asm -V<span>=</span>full
asm       <span>30863</span>  <span>30825</span>  asm -V<span>=</span>full
asm       <span>30872</span>  <span>30825</span>  asm -V<span>=</span>full
cgo       <span>30877</span>  <span>30825</span>  cgo -objdir /tmp/go-build130487924/b003/ ...
arm-linux-30882  <span>30877</span>  /usr/bin/arm-linux-gnueabihf-gcc -E -dM ...
cc1       <span>30883</span>  <span>30882</span>  /usr/lib/gcc-cross/arm-linux-gnueabihf/7/cc1 -E ...
...
</code></pre></div><figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/cgo-gcc-cross-compile.svg" alt="diagram with the steps taken to properly cross compile CGO "/>

    
</figure>

<p>Now, with the Concourse binary built, we can move to its dependencies.</p>
<h3 id="building-guardian-the-containerizer">Building Guardian, the containerizer</h3>
<p>As Concourse steps and resource checks run in Containers<sup>1</sup>, and there’s a piece of the Concourse worker that is responsible for that, but Concourse as a team is not necessarily in the business of creating container runtimes, Concourse uses a separate component for doing so: <a href="https://github.com/cloudfoundry/guardian">Guardian</a>(<code>gdn</code>), an implementation of the <a href="https://github.com/cloudfoundry/garden">Garden</a> interface for container management.</p>
<p>With the process of creating Linux containers being all standardized now (see <a href="https://github.com/opencontainers/runtime-spec">opencontainers/runtime-spec</a>), Guardian takes the approach of leveraging what’s already there, wrapping <a href="https://github.com/opencontainers/runc"><code>runc</code></a>, the <em>de facto</em> implementation of the Runtime Spec, allowing consumers of the Garden interface to have containers created by Runc, without leaking the implementation details to the Garden interface.</p>
<figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/please-create-a-container.svg" alt="illustration of Concourse interatinig with Garden to create a container "/>

    
</figure>

<p>The detail here though, is that while most of <code>gdn</code> is pure Go, there are many bits from <code>runc</code> (<code>gdn</code>’s dependency) that are C based, and Guardian itself depends on other binaries (one being a C program).</p>
<figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/gdn-dependencies.svg" alt="Guardian dependencies "/>

    
</figure>

<p>Another detail in the process os building <code>gdn</code> is that, by default, <code>gdn</code> is not suitable for multiple architectures due to the way the way that it interacts with <code>runc</code> when it comes to asking <code>runc</code> to block specific syscalls.</p>
<figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/seccomp-limitting.svg" alt="seccomp in action, limiting the system calls that a process can use "/>

    
</figure>

<div><pre><code data-lang="go"><span>// Seccomp represents syscall restrictions
</span><span>//
</span><span>// By default, only the native architecture of the kernel is allowed to be used
</span><span>// for syscalls. Additional architectures can be added by specifying them in
</span><span>// Architectures.
</span><span>//
</span><span></span><span>type</span> <span>Seccomp</span> <span>struct</span> <span>{</span>
	<span>DefaultAction</span> <span>Action</span>     <span>`json:&#34;default_action&#34;`</span>
	<span>Architectures</span> <span>[]</span><span>string</span>   <span>`json:&#34;architectures&#34;`</span>
	<span>Syscalls</span>      <span>[]</span><span>*</span><span>Syscall</span> <span>`json:&#34;syscalls&#34;`</span>
<span>}</span>
</code></pre></div><p>That means that, in <code>gdn</code> itself, we needed to have in the <code>architectures</code> slice, ARM included:</p>
<div><pre><code data-lang="diff"> var seccomp = &amp;specs.LinuxSeccomp{
         DefaultAction: specs.ActErrno,
         Architectures: []specs.Arch{
                 specs.ArchX86_64,
                 specs.ArchX86,
                 specs.ArchX32,
<span>+                specs.ArchARM,
</span><span></span>         },
         Syscalls: []specs.LinuxSyscall{
</code></pre></div><p>As we know how to build all of those in a cross-platform way, we just need to follow the same recipe: set the right compiler, and there you go.</p>
<p><i><sup>1</sup>: in platforms that support containers.</i></p>
<h3 id="building-baggageclaim-the-volumizer">Building Baggageclaim, the volumizer</h3>
<p>As mentioned before, the “volumizer” is already part of the worker, thus, by building <code>concourse</code> (the binary), we already have <code>baggageclaim</code> built.</p>
<p>The only detail for <code>baggageclaim</code> is that if the backing filesystem for it is set to be <code>btrfs</code>, then the machine that runs the worker needs to have the <code>btrfs</code> CLI on it (built to the right platform).</p>
<h3 id="running-the-concourse-worker">Running the Concourse worker</h3>
<p>At this point, we can already have our Concourse worker in a state that it could run - it has all of its dependencies, even though it has no base <a href="https://concourse-ci.org/resource-types.html">resource types</a>, meaning that it wouldn’t be able to have any steps or even checks running.</p>
<p>The reason for that is that the root filesystem that ends up being fetched by Concourse to run a container needs to come from somewhere - the resource type that is configured to retrieve those bits. As there are none to do so, nothing fetch the base, thus, nothing can run.</p>
<figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/rootfs-retrieval.svg" alt="illustration of the interaction between web and worker components in Concourse "/>

    
</figure>

<p>To break out of that, we have to create a resource type to ship with our cross platform build that is able to retrieve root filesystems that are built for the specific platform that we target.</p>
<p>As we’re targetting non Linux AMD64, that meant that we’d need to go through the cross compilation dance again, now for the <a href="https://github.com/concourse/registry-image-resource"><code>registry-image</code> resource</a>.</p>
<p>The problem though, is that not only compiling would be sufficient - when a registry client asks for a container image that lives in a registry, it has to specify what’s the platform that such image is created for.</p>
<figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/registry-image-resource-interaction.svg" alt="illustration of the registry-image-resource interaction with container creation and a container images registry "/>

    
</figure>

<p>By default, the underlying library that <code>registry-image-resource</code> uses assuming the <code>linux</code> <code>amd64</code> tuple, thus, I created a pull request (PR) to address that: <a href="https://github.com/concourse/registry-image-resource/pull/36">https://github.com/concourse/registry-image-resource/pull/36</a>.</p>
<h3 id="generating-the-modified-registry-image-resource">Generating the modified registry-image-resource</h3>
<p>As a base resource type is defined by having a <code>rootfs</code> and <code> resource_metadata.json</code> (see <a href="https://concourse-ci.org/tasks.html#task-image-resource),">https://concourse-ci.org/tasks.html#task-image-resource),</a> the easiest way of getting to a <code>rootfs</code> would be to have a container image generated from a Dockerfile and then extracting the final rootfs, and placing that into a tarball.</p>
<p>Having that <code>rootfs.tgz</code> that contains the root filesystem for the modified <code>registry-image-resource</code>, that would mean that I could then distribute this resource in the tarball that contains all of the necessary bits for Concourse, effectively bootstrapping the whole thing!</p>
<figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/concourse-tarball-distribution.svg" alt="a view into how the final tarball looks like "/>

    
</figure>

<p>While that sounds great, we have to remember that the <code>registry-image-resource</code> makes requests to external systems.</p>
<p>The problem here is that to have the <code>rootfs</code> properly created, we need to execute some commands within that container that creates the rootfs to get <code>ca-certificates</code> so that we can make requests to HTTPS endpoints.</p>
<div><pre><code data-lang="dockerfile"><span># the final representation of the registry-image </span><span>
</span><span></span><span># Concourse resource type.</span><span>
</span><span></span><span>#</span><span>
</span><span></span><span>FROM</span><span> rootfs-${arch} AS registry-image-resource</span><span>
</span><span>
</span><span></span><span>COPY</span> --from<span>=</span>registry-image-resource-build <span>\
</span><span></span>        /assets/ <span>\
</span><span></span>        /opt/resource/<span>
</span><span>
</span><span></span><span>RUN</span> apt update -y <span>&amp;&amp;</span> <span>\
</span><span></span>        apt install -y ca-certificates <span>&amp;&amp;</span> <span>\
</span><span></span>        rm -rf /var/lib/apt/lists/*<span>
</span></code></pre></div><p>As the base image of that container must be an ARM-based image, it means that any binaries that we try executing there, will be executing instructions that only ARM machines can run. Damn!</p>
<p>To overcome that, we have at least two options:</p>
<ol>
<li>create a bootstrapping container image once in the target architecture, or</li>
<li>emulate the target architecture.</li>
</ol>
<p>While <code>1</code> sounds like something that could work, <code>2</code> is now quite simple to achieve, if you’re using a MacOS or Windows 10 machine.</p>
<p>Since not too long ago, Docker for Desktop has been shipping their internal VM with the right hooks to be able to emulate other architectures in a very transparent way for the developer (see the recent announcement: <a href="https://engineering.docker.com/2019/04/multi-arch-images/">Building Multi-Arch Image for Arm and X86 with Docker Desktop</a>).</p>
<h3 id="automating-the-process-of-building-an-arm-based-concourse-distribution">Automating the process of building an ARM-based Concourse distribution</h3>
<p>As manually building all of those binaries is not fun at all, I made the whole process buildable by creating a <a href="https://docs.docker.com/develop/develop-images/multistage-build/">multi-stage Dockerfile</a> (see <a href="https://github.com/cirocosta/concourse-arm/blob/master/Dockerfile"><code>cirocosta/concourse-arm#Dockerfile</code></a>).</p>
<p>Given that to build such Dockerfile we’d need to have a task that is able to do so, the Dockerfile builds a version of the <a href="https://github.com/concourse/builder-task"><code>builder-task</code></a>, which wraps <a href="https://github.com/genuinetools/img"><code>genuinetools/img</code></a>, which is able to build container images from Dockerfiles (using <a href="https://github.com/moby/buildkit">buildkit</a>).</p>
<p>Yeah, that’s a <em>lot</em> of names in a single article!</p>
<h3 id="summarizing">Summarizing</h3>
<p>In the end, we build a bunch of stuff!</p>
<p>For instance, consider the building of the binaries:</p>
<figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/binaries.svg" alt="diagram of all of the steps taken to build the binaries container image "/>

    
</figure>

<p>And, for the <code>registry-image-resource</code> rootfs:</p>
<figure>
    <img width="100%" height="100%" src="https://ops.tips/blog/-/images/registry-image-resource.svg" alt="diagram with the steps taken to build the registry-image-resource bts "/>

    
</figure>

<p>The good news is that it’s all declared in that very same Dockerfile I mentioned, making the build mostly reproducible.</p>
<h3 id="some-surprises">Some surprises</h3>
<ul>
<li>
<p>While trying to figure out what was going wrong with Guardian, I wanted <strong>so much</strong> to use <a href="https://github.com/go-delve/delve"><code>dlv</code></a> to troubleshoot what was going on, but, unfortunatelly, it doesn’t support any 32bit systems at the moment.</p>
</li>
<li>
<p>I didn’t know that in some Linux distros you’d have to run <code>modprobe config</code> to have the <code>/proc/config.gz</code> file accessible to check the configuration used to build that Kernel - interesting to know!</p>
</li>
</ul>
<h3 id="closing-thoughts">Closing Thoughts</h3>
<p>In the end, it turns out that it’s not super complicated to achieve building a Go project that depends on some dependencies (having some C code involved too) to other architectures - set the right variables here and there, make use of some emulation if needed, and there you go.</p>
<p>It’s quite cool what you can do using cross compilation, and how a combination of Go and container images with a well defined set of build steps can make the whole process of building for multi platforms work great even when you don’t have access to those platforms.</p>
<p>I’m very curious about the whole movement of supporting other architectures other than amd64, so it’s nice to start having a foot in this space.</p>
<p>Even though we made use of cross compilation, there were steps where we were still needing to run some details in such architecture, which makes me think that it might be worth investing in having Concourse workers running smoothly on these other platforms too.</p>
<p>Please let me know what you think! I’m <a href="https://twitter.com/cirowrc">@cirowrc</a> on Twitter.</p>
<p>See you!</p>

    </section>
  </article></div>
        </section>
    </article>
</main>
</body>
</html>
